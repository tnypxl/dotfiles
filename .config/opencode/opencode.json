{
  "$schema": "https://opencode.ai/config.json",
  "permission": {
    "external_directory": {
      "~/.config/opencode/get-shit-done/*": "allow"
    },
    "read": {
      "~/.config/opencode/get-shit-done/*": "allow"
    }
  },
  "provider": {
    "ollama": {
      "models": {
        "glm-4.7-flash:latest": {
          "name": "glm-4.7-flash:latest"
        }
      },
      "name": "Ollama (local)",
      "npm": "@ai-sdk/openai-compatible",
      "options": {
        "baseURL": "http://localhost:11434/v1"
      }
    }
  }
}
